{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Methods import latin_Corpus, ldamodel, highest_topic_search, find_other_highest\n",
    "from cltk.stem.lemma import LemmaReplacer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from cltk.stop.latin.stops import STOPS_LIST\n",
    "from cltk.vector.word2vec import get_sims\n",
    "from gensim import corpora, models\n",
    "import re, pprint\n",
    "from urllib import request\n",
    "import gensim\n",
    "from cltk.corpus.utils.importer import CorpusImporter\n",
    "corpus_importer = CorpusImporter('latin')\n",
    "corpus_importer.import_corpus('latin_models_cltk')\n",
    "import os\n",
    "from lxml import etree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for a regular text file, file opening and reading\n",
    "#file1 = '/home/ykim/Desktop/wodeham-b1-d3-qun-clean-html.xml'\n",
    "#book1 = open(file1, 'r').read()\n",
    "\n",
    "#for a xml doc\n",
    "tree = etree.parse(\"/home/ykim/Desktop/wodeham-b1-d3-qun-clean-html.xml\")\n",
    "corpus = tree.xpath(\"//p//text()\")\n",
    "\n",
    "#corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "lemmatizer = LemmaReplacer('latin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "197"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#how many paragraphs there are\n",
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "STOP_LIST = ['ab', 'ac', 'ad', 'adhic', 'aliqui', 'aliquis', 'an', 'ante', 'apud', 'at', 'atque', 'aut', 'autem', 'cum', 'cur', 'de', 'deinde', 'dum', 'ego', 'enim', 'ergo', 'es', 'est', 'et', 'etiam', 'etsi', 'ex', 'fio', 'haud', 'hic', 'iam', 'idem', 'igitur', 'ille', 'in', 'infra', 'inter', 'interim', 'ipse', 'is', 'ita', 'magis', 'modo', 'mox', 'nam', 'ne', 'nec', 'necque', 'neque', 'nisi', 'non', 'nos', 'o', 'ob', 'per', 'possum', 'post', 'pro', 'quae', 'quam', 'quare', 'qui', 'quia', 'quicumque', 'quidem', 'quilibet', 'quis', 'quisnam', 'quisquam', 'quisque', 'quisquis', 'quo', 'quoniam', 'sed', 'si', 'sic', 'sive', 'sub', 'sui', 'sum', 'super', 'suus', 'tam', 'tamen', 'trans', 'tu', 'tum', 'ubi', 'uel', 'uero', 'unus', 'ut', 'sum1', 'qui1', 'edo1', 'quis1', 'meus', 'tantus', 'sum1', 'suum', 'quantus', 'quidam', 'eo1', \"dico1\", 'dico2', 'f', 'quasi', 'neo1', 'inquam', 'vel', 'que', \"suo\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#corpus clean up\n",
    "new_corpus = []\n",
    "latin_Corpus(corpus, new_corpus, tokenizer,lemmatizer,STOP_LIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#creating dict of campus\n",
    "dictionary = corpora.Dictionary(new_corpus)\n",
    "\n",
    "\n",
    "#removes words that frequent more than 500 times\n",
    "dictionary.filter_n_most_frequent(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(dictionary.token2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#creates bag of words\n",
    "bags = [dictionary.doc2bow(doc) for doc in new_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, '0.068*\"penum\" + 0.017*\"complector\" + 0.017*\"causet\"'), (1, '0.024*\"desino\" + 0.024*\"hostia\" + 0.024*\"moralis\"'), (2, '0.021*\"novo\" + 0.021*\"apprehensione\" + 0.014*\"vicus\"'), (3, '0.019*\"gaudium\" + 0.014*\"ly\" + 0.014*\"duplaret\"'), (4, '0.017*\"arbor1\" + 0.017*\"collective\" + 0.017*\"pereo\"'), (5, '0.021*\"sensitivus\" + 0.021*\"intellectivus\" + 0.021*\"sitis\"'), (6, '0.026*\"delectatio\" + 0.018*\"partialis\" + 0.018*\"catholicus\"'), (7, '0.021*\"perdo\" + 0.014*\"obicio\" + 0.014*\"intensiorem\"'), (8, '0.025*\"sanitas\" + 0.025*\"pulchritudo\" + 0.017*\"consubstantialitas\"'), (9, '0.037*\"meritorius\" + 0.026*\"exsecutio\" + 0.016*\"cuiusmodi\"'), (10, '0.022*\"amabilis\" + 0.022*\"cognoscibile\" + 0.011*\"intro2\"'), (11, '0.083*\"odium1\" + 0.028*\"centrum\" + 0.021*\"Platonis\"'), (12, '0.021*\"displiceo\" + 0.021*\"ruina\" + 0.021*\"conceptio\"'), (13, '0.043*\"perceptio\" + 0.029*\"singulus\" + 0.014*\"numerales\"'), (14, '0.020*\"claritas1\" + 0.020*\"frustro\" + 0.020*\"refreno\"'), (15, '0.029*\"C\" + 0.022*\"Plato\" + 0.022*\"statuo\"'), (16, '0.016*\"causabit\" + 0.016*\"elicio\" + 0.016*\"23\"'), (17, '0.030*\"usque\" + 0.030*\"calo1\" + 0.015*\"percipio\"'), (18, '0.033*\"potus2\" + 0.033*\"cibus\" + 0.022*\"abduco\"'), (19, '0.017*\"panis\" + 0.017*\"oro\" + 0.017*\"bis\"')]\n"
     ]
    }
   ],
   "source": [
    "#lda model in use\n",
    "ldamodel = ldamodel(gensim, bags, 20, dictionary, 40, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-26d646d3ecdb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#example of the topics a paragraph has\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdoc_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mldamodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbags\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdoc_1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "#example of the topics a paragraph has\n",
    "doc_1 = ldamodel[bags[1]]\n",
    "\n",
    "doc_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-1536cc05f5a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#example of the topics a paragraph has\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdoc_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mldamodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbags\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdoc_1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "target_topic = highest_topic_search(doc_1)\n",
    "\n",
    "\n",
    "find_other_highest(target_topic, bags, 0.50)\n",
    "\n",
    "\n",
    "#target paragraph\n",
    "paranum = 0\n",
    "\n",
    "\n",
    "\n",
    "#get target paragraph's topics\n",
    "target_doc_topics = ldamodel[bags[paranum]]\n",
    "\n",
    "\n",
    "\n",
    "search_topic_array = []\n",
    "for topic in target_doc_topics:\n",
    "    search_topic_array.append(topic[0])\n",
    "\n",
    "\n",
    "search_topic_array\n",
    "\n",
    "\n",
    "#find the related topics\n",
    "result_array = []\n",
    "counter = 0\n",
    "for bag in bags:\n",
    "    doc = ldamodel[bag]\n",
    "    print(doc)\n",
    "    for t in doc:    \n",
    "        if t[0] in search_topic_array:\n",
    "            result_array.append((counter, t[1], t[0]))\n",
    "    counter += 1\n",
    "\n",
    "\n",
    "#result_array\n",
    "\n",
    "\n",
    "#sort them by most similar\n",
    "result_array.sort(key = lambda x:x[1], reverse = True)\n",
    "\n",
    "\n",
    "\n",
    "result_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
